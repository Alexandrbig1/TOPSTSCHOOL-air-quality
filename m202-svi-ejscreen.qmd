---
title: "SVI, TRI, and Health Outcomes"
format: html
---

## Overview

In this lesson, you will use....

## Learning Objectives

After completing this lesson, you should be able to:

-   Manipulating and processing raster data; mainly loading and cropping.
-   Exploring SVI/raster by mapping and processing different sub datasets (overall/racial/socioeconomic).
-   Connecting to APIâ€™s for pollution and public health data.
-   Geolocating tabular data with latitude and longitude.
-   Joining tabular data to spatial data (probably polygons).
-   Connecting to OpenStreetMap API for basemaps.
-   Creating regional basemaps.
-   Layering spatial data on basemaps.
    -   Semi-transparent SVI, TRI points, PLACES boundaries.
-   Creating maps with graduated point symbols for point source pollution releases.
-   Creating choropleths with census tract polygons for health outcomes data.
-   Zonal statistics with census tracts for:
    -   Mean SVI values

    -   Health outcomes summaries weighted by SVI.
-   (Maybe) Interpolate pollution load raster surface from point data.
-   Spatial correlation analysis between SVI, point pollution, and health outcomes. .

## Introduction

-   Lots of opportunities for different background information.

-   General air quality issues and EPA.

-   Air pollution data and data availability.

-   Social vulnerability, EJ, and NIMBY.

-   The difficulty of assessing health outcomes and types of publicly available data.

-   Possible brief discussion on scale and appropriate data.

## Load the Data

SVI has a primary overall SVI score, but also provides sublayers. These include minority, socioeconomic, housing, and household data.

```{python}
import xarray as xr
import rasterio
import rasterio.mask
import geopandas as gpd
import matplotlib.pyplot as plt
import pygris
import numpy as np

# Fetch Detroit boundary using pygris
detroit = pygris.places(state="MI", year=2022)
detroit = detroit[detroit['NAME'] == 'Detroit']

# Convert to GeoDataFrame (it already is, but let's ensure it)
detroit = gpd.GeoDataFrame(detroit, geometry='geometry', crs='EPSG:4269')

# Specify the TIF files
tif_files = [
    "data/svi/svi_2020_tract_overall_wgs84.tif",
    "data/svi/svi_2020_tract_minority_wgs84.tif",
    "data/svi/svi_2020_tract_socioeconomic_wgs84.tif",
    "data/svi/svi_2020_tract_housing_wgs84.tif",
    "data/svi/svi_2020_tract_household_wgs84.tif"
]

# Create an empty list to store the individual DataArrays
data_arrays = []

# Read each TIF file, clip it to Detroit's extent, and append it to the list
for file in tif_files:
    with rasterio.open(file) as src:
        # Reproject Detroit boundary to match the raster CRS
        detroit_reprojected = detroit.to_crs(src.crs)
        
        # Clip the raster to Detroit's geometry
        out_image, out_transform = rasterio.mask.mask(src, detroit_reprojected.geometry, crop=True)
        out_meta = src.meta.copy()
        
        # Update the metadata
        out_meta.update({"driver": "GTiff",
                         "height": out_image.shape[1],
                         "width": out_image.shape[2],
                         "transform": out_transform})
        
        # Create coordinates
        height = out_meta['height']
        width = out_meta['width']
        cols, rows = np.meshgrid(np.arange(width), np.arange(height))
        xs, ys = rasterio.transform.xy(out_transform, rows, cols)
        
        # Convert lists to numpy arrays
        xs = np.array(xs)
        ys = np.array(ys)
        
        # Reshape coordinates to match dimensions of the raster
        xs = xs.reshape(height, width)
        ys = ys.reshape(height, width)
        
        # Create a DataArray from the clipped data
        da = xr.DataArray(out_image[0],  # Use the first band
                          coords={'y': ('y', ys[:, 0]),
                                  'x': ('x', xs[0, :])},
                          dims=['y', 'x'])
        da.attrs['crs'] = str(src.crs)  # Convert CRS to string
        da.attrs['transform'] = out_transform
        data_arrays.append(da)

# Combine all DataArrays into a single DataSet
ds = xr.concat(data_arrays, dim='layer')

# Rename the layers using the appropriate dimension
ds = ds.assign_coords(layer=('layer', ['Overall', 'Minority', 'Socioeconomic', 'Housing', 'Household']))

# Define the colorbar limits
vmin, vmax = 0, 1

# Create a multipanel plot
fig, axes = plt.subplots(3, 2, figsize=(15, 20))
axes = axes.flatten()

# Plot each layer
for i, layer in enumerate(ds.layer.values):
    # Plot with custom color limits
    im = ds.sel(layer=layer).plot(ax=axes[i], add_colorbar=False, vmin=vmin, vmax=vmax)
    axes[i].set_title(layer)
    
    # Plot Detroit boundary
    detroit_reprojected.boundary.plot(ax=axes[i], color='red', linewidth=1)

# Remove the extra subplot
fig.delaxes(axes[5])

# Add a single colorbar with a custom range
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
cbar = fig.colorbar(im, cax=cbar_ax, label='SVI Score')

# Set the colorbar limits
cbar.set_clim(vmin, vmax)

plt.tight_layout()
plt.show()
```

```{python}
import geopandas as gpd
import matplotlib.pyplot as plt
import contextily as ctx
import requests
from shapely.geometry import Point

# Step 1: Define the area of interest (Detroit, MI)
detroit_bounds = [-83.287, 42.255, -82.910, 42.450]  # [min_lon, min_lat, max_lon, max_lat]

# Step 2: Fetch TRI facility data from EPA API
api_url = "https://data.epa.gov/efservice/tri_facility/state_abbr/MI/city_name/DETROIT/JSON"
response = requests.get(api_url)
tri_data = response.json()

print(f"Number of facilities fetched: {len(tri_data)}")

# Step 3: Create a GeoDataFrame from the TRI facility data
valid_facilities = []
geometry = []

for facility in tri_data:
    if facility['pref_latitude'] is not None and facility['pref_longitude'] is not None:
        valid_facilities.append(facility)
        lon, lat = -float(facility['pref_longitude']), float(facility['pref_latitude'])  # Note the negative sign for longitude
        geometry.append(Point(lon, lat))
        print(f"Facility coordinates: {lon}, {lat}")  # Debug print

print(f"Number of valid facilities: {len(valid_facilities)}")

gdf = gpd.GeoDataFrame(valid_facilities, geometry=geometry, crs="EPSG:4326")

print(f"GeoDataFrame shape: {gdf.shape}")
print(gdf.head())

# Step 4: Create the map
fig, ax = plt.subplots(figsize=(12, 8))

# Step 5: Plot the data
gdf.plot(ax=ax, color='purple', markersize=50, alpha=0.7)

# Step 6: Set the extent
ax.set_xlim(detroit_bounds[0], detroit_bounds[2])
ax.set_ylim(detroit_bounds[1], detroit_bounds[3])

# Step 7: Add the basemap
ctx.add_basemap(ax, crs=gdf.crs, source=ctx.providers.OpenStreetMap.Mapnik)

# Step 8: Customize the map
ax.set_axis_off()
plt.title("Toxic Release Inventory Facilities in Detroit, MI", fontsize=16)

# Step 9: Show the map
plt.tight_layout()
plt.show()
```
```{python}
# places asthma url
"https://data.cdc.gov/resource/cwsq-ngmh.json?stateabbr=MI&measure=Current%20asthma%20among%20adults%20aged%20%3E=18%20years"
```

```{python}
import requests
import json
import pandas as pd
import plotly.express as px
import zipfile
import io

# Base URL for CDC PLACES GIS Tract Data
base_url = "https://chronicdata.cdc.gov/resource/yjkw-uj5s.geojson"

# Parameters for Michigan census tracts, including asthma data
params = {
    "stateabbr": "MI",
    "$limit": 5000  # Adjust this if there are more tracts
}

# Make the API request
response = requests.get(base_url, params=params)
response

data = response.json()
    
    # Convert to DataFrame
    gdf = gpd.GeoDataFrame.from_features(data['features'])

census_tracts = pygris.tracts(state = "MI")

    # Define the URL for the shapefile zip file from the Census Bureau
url = 'https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_tract_20m.zip'

# Fetch the zip file from the URL
response = requests.get(url)
with zipfile.ZipFile(io.BytesIO(response.content)) as z:
    # Extract the shapefile from the zip file
    z.extractall('cb_2023_us_tract_20m.zip')

# Load the shapefile into a GeoDataFrame
census_tracts = gpd.read_file('cb_2023_us_tract_20m/cb_2023_us_tract_20m.shp')

    # Assuming 'gdf' is your GeoDataFrame and it has a column named 'value' for the choropleth colors
fig = px.choropleth(
    gdf,
    geojson=gdf.geometry,
    locations=gdf.index,
    color='casthma_crudeprev',
    hover_name=gdf.index,  # or any column you want to show on hover
    projection="mercator"
)

fig.update_geos(fitbounds="locations", visible=False)
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})

fig.show()

    # Create the choropleth map
    fig = px.choropleth(
        df,
        geojson="https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json",
        locations="tractfips",
        color="asthma_crude_prev",
        scope="usa",
        labels={"asthma_crude_prev": "Asthma Prevalence (%)"},
        title="Asthma Prevalence in Michigan Census Tracts",
        hover_data=["tractfips", "asthma_crude_prev"]
    )
    
    # Update the map layout to zoom in on Michigan
    fig.update_geos(
        visible=False,
        scope="usa",
        center={"lat": 44.3148, "lon": -85.6024},
        projection_scale=5,
    )
    
    # Show the map
    fig.show()
    
    print(f"Choropleth map created with {len(df)} census tracts.")
else:
    print(f"Error: Unable to fetch data. Status code: {response.status_code}")
    print(response.text)
```

```{python}
import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
import requests
import io

# Step 1: Install required libraries (if not already installed)
# !pip install geopandas pandas matplotlib requests

# Step 2: Download CDC Places data for Detroit
url = "https://data.cdc.gov/resource/cwsq-ngmh.json?stateabbr=MI&measure=Current%20asthma%20among%20adults%20aged%20%3E=18%20years"
detroit_data = pd.read_json(url)

# Filter for Detroit and the asthma measure
detroit_asthma = detroit_data[(detroit_data['PlaceName'] == 'Detroit') & 
                              (detroit_data['MeasureId'] == 'CASTHMA')]

# Step 3: Download GeoJSON for Detroit
detroit_geojson_url = "https://opendata.arcgis.com/datasets/0d44a906548244378396dd9e89560d9a_0.geojson"
response = requests.get(detroit_geojson_url)
detroit_gdf = gpd.read_file(io.BytesIO(response.content))

# Merge the asthma data with the GeoJSON
merged_gdf = detroit_gdf.merge(detroit_asthma, left_on='zip', right_on='LocationName')

# Step 4: Create the choropleth map
fig, ax = plt.subplots(1, 1, figsize=(15, 10))
merged_gdf.plot(column='Data_Value', 
                ax=ax, 
                legend=True, 
                legend_kwds={'label': 'Asthma Prevalence (%)', 'orientation': 'horizontal'},
                cmap='YlOrRd',
                missing_kwds={'color': 'lightgrey'})

ax.set_title('Adult Asthma Prevalence in Detroit, MI')
ax.axis('off')

plt.tight_layout()
plt.show()
```
### Deployment


Congratulations! .... Now you should be able to:

-   Test test...

## Lesson 3

In this lesson, we explored ....

[Lesson 3](https://ciesin-geospatial.github.io/TOPSTSCHOOL-air-quality/m203-grdiv1-pm25.html){.btn .btn-primary .btn role="button"}