[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome SCHOOL Module 2: Air Quality",
    "section": "",
    "text": "Welcome to the second module of the SCHOOL curriculum!\nThe Science Core Heuristics for Open Science Outcomes in Learning (SCHOOL) is part of the NASA Transform to Open Science (TOPS) Training (TOPST) initiative, designed to teach the data science lifecycle using data from the NASA Earth Sciences division and to foster an inclusive culture of open science. You can learn more about the SCHOOL Project and other modules on the SCHOOL Project home page.\nThe second SCHOOL module on the theme of “Air Quality and Health” explores how particulates in the air impact humans and how they are affected by the changes in air quality. The module consists of three use cases that cover examples of …… and …. such as …..\nEach use case uses a unique dataset to walk users through lessons in accessing and analyzing data, and further adapting the code to perform their analyses including data cleaning, processing to subset to an area of interest, and creating visualizations to share what they have learned with their communities.\nThis module is tailored to instruct undergraduate students and early-career researchers with some coding language exposure about the data science life cycle, illustrating how Open Science principles can be effectively applied to earth sciences, particularly in the context of water.\nThe SCHOOL Modules do not intend to teach all-encompassing earth science lessons nor provide learners with total coding expertise. Instead, the SCHOOL Project aims to provide users with the skills to adapt the SCHOOL lessons to the users’ own Open Science workflow. To learn more about Open Science, explore NASA’s TOPS Open Science 101 Curriculum. To explore other themes in the SCHOOL project, visit our Modules Page.\nModule 2: Air Quality datasets and use cases cover:\n\nEnabling Student-led Air Quality and Extreme Temperature Monitoring in New York: Examining the relationship between two environmental hazards – hazardous air quality and temperature – and socioeconomic characteristics of New York State (NYS) schools.\n\nLesson 1: Acquiring, Pre-Processing, and Visualizing Student-Monitored Data for New York City (NYC) Schools\n\nSocial Vulnerability Index (SVI) Social Determinants of Health, and the EJScreen: Environmental Justice Screening and Mapping Tool: Exploring social determinants of health within the USA with the SVI; EJScreen is the Environmental justice mapping and screening tool that helps users understand the environmental and demographic characteristics of a specific area.\n\nLesson 2: Exploring the Social Vulnerability Index (SVI) Social Determinants of Health, and the EJScreen: Environmental Justice Screening and Mapping Tool\n\nGlobal Gridded Relative Deprivation Index Version 1 (GRDIv1), and the Global (GL) Annual PM2.5 Grids from MODIS, MISR and SeaWiFS Aerosol Optical Depth: Analyzing the global relationships between socioeconomic vulnerability and particulate matter concentrations over years.\n\nLesson 3: Global Gridded Relative Deprivation Index Version 1 (GRDIv1) and the Global Annual PM2.5 Grids\n\n\n\nStart Lesson 1\n\nThis course was made possible thanks to the work of our NASA Transform to Open Science (TOPS) team, our SCHOOL Open Science team, open science Subject Matter Experts (SMEs), and the SCHOOL Development team!"
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html",
    "href": "m201-student-led-monitoring-nyc.html",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "",
    "text": "In this lesson, you will use…."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#learning-objectives",
    "href": "m201-student-led-monitoring-nyc.html#learning-objectives",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to:\n\nDetermine…"
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#introduction",
    "href": "m201-student-led-monitoring-nyc.html#introduction",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Introduction",
    "text": "Introduction\nThis project, “Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York,” led by Carolynne Hultquist and her team, aims to engage students in monitoring environmental hazards, specifically hazardous air quality and extreme temperature, outside and inside New York State schools. The focus is on New York City (NYC) schools serving low-income minority populations located in environmental justice communities characterized by high levels of hazard exposure. By incorporating mobile and static monitoring techniques, students contribute to data collection and analysis, integrating satellite data and sensor networks. This initiative not only provides valuable data on environmental conditions but also educates students on the principles of open science and the data science life cycle."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#data-collection-and-preparation",
    "href": "m201-student-led-monitoring-nyc.html#data-collection-and-preparation",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Data Collection and Preparation",
    "text": "Data Collection and Preparation\n\nMobile and Static Monitoring\nEquip students with mobile sensors to collect air quality data. Compare this with data from static sensors placed in schools and remote sensing sources.\n\n\nSatellite Data Integration\nUtilize satellite data such as MODIS, OMI, MERRA-2, GOES, CHIRTS-daily, and SEDAC’s Air Quality Data to complement ground data.\n\n\nData Upload and Management\nStudents upload collected data to an online platform, ensuring proper documentation and metadata inclusion to maintain data quality and integrity."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#data-cleaning-and-preprocessing",
    "href": "m201-student-led-monitoring-nyc.html#data-cleaning-and-preprocessing",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Data Cleaning and Preprocessing",
    "text": "Data Cleaning and Preprocessing\n\nData Validation\nCheck for inconsistencies or anomalies in the collected data. This includes cross-referencing mobile sensor data with static and satellite data to ensure accuracy.\n\n\nHandling Missing Data\nApply techniques such as interpolation or imputation to address missing data points, ensuring a complete dataset for analysis."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#data-analysis-and-visualization",
    "href": "m201-student-led-monitoring-nyc.html#data-analysis-and-visualization",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Data Analysis and Visualization",
    "text": "Data Analysis and Visualization\n\nDescriptive Statistics\nCalculate basic statistics (mean, median, mode, standard deviation) to understand the distribution and central tendencies of the data.\n\n\nCorrelation Analysis\nExamine relationships between air quality, temperature, and socioeconomic characteristics of the schools.\n\n\nVisualization\nUse tools like ArcGIS Online for participatory mapping and visualizations to represent data spatially and temporally. Modeling and Interpretation\n\n\nPredictive Modeling\nDevelop models to predict air quality and temperature variations based on historical data and current trends. Impact Analysis: Assess the health impacts of hazardous air quality and extreme temperatures on school populations, with a focus on vulnerable groups. Reporting and Communication\n\n\nStory Development\nEngage with the Solutions Journalism Network to develop stories that highlight the project’s findings and advocate for environmental justice.\n\n\nPublications and Presentations\nCompile findings into reports, articles, and presentations for dissemination through academic channels and public forums."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#open-science-principles-and-data-sharing",
    "href": "m201-student-led-monitoring-nyc.html#open-science-principles-and-data-sharing",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Open Science Principles and Data Sharing",
    "text": "Open Science Principles and Data Sharing\n\nTransparency\nEnsure all data processing steps, methodologies, and code are well-documented and accessible.\n\n\nReproducibility\nProvide clear instructions and datasets for others to replicate the study.\n\n\nData Sharing\nPublish datasets and findings in open-access repositories to promote further research and collaboration.\nCongratulations! …. Now you should be able to:\n\nTest test."
  },
  {
    "objectID": "m201-student-led-monitoring-nyc.html#lesson-2",
    "href": "m201-student-led-monitoring-nyc.html#lesson-2",
    "title": "Enabling Student-led Air Quality and Extreme Temperature Monitoring in New York",
    "section": "Lesson 2",
    "text": "Lesson 2\nIn this lesson, we explored ….\nLesson 2: EJSCREEN"
  },
  {
    "objectID": "m202-ejscreen.html",
    "href": "m202-ejscreen.html",
    "title": "EJSCREEN tool",
    "section": "",
    "text": "In this lesson, you will use…."
  },
  {
    "objectID": "m202-ejscreen.html#learning-objectives",
    "href": "m202-ejscreen.html#learning-objectives",
    "title": "EJSCREEN tool",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to:\n\nDetermine…"
  },
  {
    "objectID": "m202-ejscreen.html#introduction",
    "href": "m202-ejscreen.html#introduction",
    "title": "EJSCREEN tool",
    "section": "Introduction",
    "text": "Introduction\nIn recent years, researchers have explored the intersection between environmental factors and public health, particularly concerning diseases like COVID-19 and non-small cell lung cancer (NSCLC). Studies have highlighted the impact of air pollution on disease susceptibility and outcomes, emphasizing the need for rigorous analysis and understanding of these relationships. This overview focuses on several key studies that utilize data science principles to investigate how environmental justice, air pollution, and demographic factors intersect, providing insights that contribute to open science principles and the data science life cycle."
  },
  {
    "objectID": "m202-ejscreen.html#data-collection-and-integration",
    "href": "m202-ejscreen.html#data-collection-and-integration",
    "title": "EJSCREEN tool",
    "section": "Data Collection and Integration",
    "text": "Data Collection and Integration\nGather comprehensive datasets from reliable sources such as the US EPA’s EJSCREEN tool and other public health databases like John Hopkins and County Health Rankings. Integrate relevant environmental data (e.g., air pollutant concentrations, pollution source proximity) with health outcomes data (e.g., COVID-19 prevalence, NSCLC incidence). Ensure data compatibility and quality through data cleaning and validation procedures.\n\nExploratory Data Analysis (EDA)\nConduct initial exploratory analyses to understand the distribution and relationships within the data. Visualize data using plots and charts to identify patterns and correlations between environmental factors, demographic variables, and health outcomes. Perform statistical tests to assess associations and identify potential confounding factors.\n\n\nModel Development and Analysis\nApply statistical models (e.g., regression analyses, machine learning algorithms) to quantify the relationships between environmental exposures and health outcomes. Adjust for confounders such as demographic characteristics (e.g., age, race/ethnicity) and socioeconomic factors (e.g., income, education). Validate models using cross-validation techniques to ensure robustness and generalizability of findings.\n\n\nInterpretation and Communication of Results\nInterpret findings in the context of environmental justice principles, highlighting disparities and vulnerabilities observed in different populations. Discuss implications for public health policy and environmental regulations based on study outcomes. Communicate results transparently using accessible language and visual aids to engage stakeholders and the broader community."
  },
  {
    "objectID": "m202-ejscreen.html#the-data-science-life-cycle",
    "href": "m202-ejscreen.html#the-data-science-life-cycle",
    "title": "EJSCREEN tool",
    "section": "The Data Science Life Cycle",
    "text": "The Data Science Life Cycle\nThe data science life cycle guides the systematic approach to handling data from collection to interpretation:\n\nData Acquisition\nObtain relevant datasets from sources like EJSCREEN, County Health Rankings, and specific studies’ databases. ### Data Preparation Clean and preprocess data to ensure accuracy and consistency, handling missing values and outliers appropriately.\n\n\nExploratory Data Analysis\nExplore data distributions, correlations, and initial insights to guide further analysis.\n\n\nModeling\nDevelop statistical models to test hypotheses and predict outcomes, considering factors like pollution exposure and demographic variables.\n\n\nEvaluation\nAssess model performance and validity through metrics and cross-validation techniques.\n\n\nDeployment\nCommunicate findings through reports, presentatio\nCongratulations! …. Now you should be able to:\n\nTest test…"
  },
  {
    "objectID": "m202-ejscreen.html#lesson-2",
    "href": "m202-ejscreen.html#lesson-2",
    "title": "EJSCREEN tool",
    "section": "Lesson 2",
    "text": "Lesson 2\nIn this lesson, we explored ….\nLesson 2: EJSCREEN"
  },
  {
    "objectID": "m202-ejscreen.html#lesson-3",
    "href": "m202-ejscreen.html#lesson-3",
    "title": "EJSCREEN tool",
    "section": "Lesson 3",
    "text": "Lesson 3\nIn this lesson, we explored ….\nLesson 3"
  },
  {
    "objectID": "m202-svi-ejscreen.html",
    "href": "m202-svi-ejscreen.html",
    "title": "EJSCREEN tool",
    "section": "",
    "text": "In this lesson, you will use…."
  },
  {
    "objectID": "m202-svi-ejscreen.html#learning-objectives",
    "href": "m202-svi-ejscreen.html#learning-objectives",
    "title": "EJSCREEN tool",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to:\n\nDetermine…"
  },
  {
    "objectID": "m202-svi-ejscreen.html#introduction",
    "href": "m202-svi-ejscreen.html#introduction",
    "title": "EJSCREEN tool",
    "section": "Introduction",
    "text": "Introduction\nIn recent years, researchers have explored the intersection between environmental factors and public health, particularly concerning diseases like COVID-19 and non-small cell lung cancer (NSCLC). Studies have highlighted the impact of air pollution on disease susceptibility and outcomes, emphasizing the need for rigorous analysis and understanding of these relationships. This overview focuses on several key studies that utilize data science principles to investigate how environmental justice, air pollution, and demographic factors intersect, providing insights that contribute to open science principles and the data science life cycle."
  },
  {
    "objectID": "m202-svi-ejscreen.html#data-collection-and-integration",
    "href": "m202-svi-ejscreen.html#data-collection-and-integration",
    "title": "EJSCREEN tool",
    "section": "Data Collection and Integration",
    "text": "Data Collection and Integration\nGather comprehensive datasets from reliable sources such as the US EPA’s EJSCREEN tool and other public health databases like John Hopkins and County Health Rankings. Integrate relevant environmental data (e.g., air pollutant concentrations, pollution source proximity) with health outcomes data (e.g., COVID-19 prevalence, NSCLC incidence). Ensure data compatibility and quality through data cleaning and validation procedures.\n\nExploratory Data Analysis (EDA)\nConduct initial exploratory analyses to understand the distribution and relationships within the data. Visualize data using plots and charts to identify patterns and correlations between environmental factors, demographic variables, and health outcomes. Perform statistical tests to assess associations and identify potential confounding factors.\n\n\nModel Development and Analysis\nApply statistical models (e.g., regression analyses, machine learning algorithms) to quantify the relationships between environmental exposures and health outcomes. Adjust for confounders such as demographic characteristics (e.g., age, race/ethnicity) and socioeconomic factors (e.g., income, education). Validate models using cross-validation techniques to ensure robustness and generalizability of findings.\n\n\nInterpretation and Communication of Results\nInterpret findings in the context of environmental justice principles, highlighting disparities and vulnerabilities observed in different populations. Discuss implications for public health policy and environmental regulations based on study outcomes. Communicate results transparently using accessible language and visual aids to engage stakeholders and the broader community."
  },
  {
    "objectID": "m202-svi-ejscreen.html#the-data-science-life-cycle",
    "href": "m202-svi-ejscreen.html#the-data-science-life-cycle",
    "title": "EJSCREEN tool",
    "section": "The Data Science Life Cycle",
    "text": "The Data Science Life Cycle\nThe data science life cycle guides the systematic approach to handling data from collection to interpretation:\n\nData Acquisition\nObtain relevant datasets from sources like EJSCREEN, County Health Rankings, and specific studies’ databases. ### Data Preparation Clean and preprocess data to ensure accuracy and consistency, handling missing values and outliers appropriately.\n\n\nExploratory Data Analysis\nExplore data distributions, correlations, and initial insights to guide further analysis.\n\n\nModeling\nDevelop statistical models to test hypotheses and predict outcomes, considering factors like pollution exposure and demographic variables.\n\n\nEvaluation\nAssess model performance and validity through metrics and cross-validation techniques.\n\n\nDeployment\nCommunicate findings through reports, presentatio\nCongratulations! …. Now you should be able to:\n\nTest test…"
  },
  {
    "objectID": "m202-svi-ejscreen.html#lesson-3",
    "href": "m202-svi-ejscreen.html#lesson-3",
    "title": "EJSCREEN tool",
    "section": "Lesson 3",
    "text": "Lesson 3\nIn this lesson, we explored ….\nLesson 3"
  },
  {
    "objectID": "m203-grdiv1-pm25.html",
    "href": "m203-grdiv1-pm25.html",
    "title": "EJSCREEN tool",
    "section": "",
    "text": "In this lesson, you will use NASA socioeconomic and environmental Earthdata available at NASA SEDAC to compare relationships between levels of socioeconomic deprivation agaisnts air quality data of particulate matter (PM) in different international administrative areas.\nThis lesson walks through the process of calculating and visualizing zonal statistics for a set of countries using raster data, focusing on GRDI country quintiles and PM2.5 concentration levels within these quintile areas. It begins by subsetting data by country and iterating over each country to extract relevant zonal statistics like mean, median, and various percentiles for each quintile. These statistics are stored in a GeoDataFrame, which is later used to create a choropleth map that visualizes specific GRDI metrics across countries. The lesson includes a detailed analysis of PM2.5 concentrations within different GRDI quartiles for selected countries. This involves clipping the raster data to each country’s geometry, filtering the data based on the GRDI quartiles, and calculating the mean PM2.5 levels for each quartile. The results are then visualized using customized plots to highlight the relationship between air quality and GRDI metrics across the selected countries."
  },
  {
    "objectID": "m203-grdiv1-pm25.html#learning-objectives",
    "href": "m203-grdiv1-pm25.html#learning-objectives",
    "title": "EJSCREEN tool",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to:\n\nGain a general understanding of what is particulate matter (PM) in the air and how it impacts human health.\nLearn about global socioeconomic dimensions of deprivation and how they are spatially represented.\nFind statistical thresholds in socioeconomic data.\nPerform zonal statistics to summarize spatial data\nResample spatial data to harmoniza and compare socioeconomic data against environmental data.\nDisplay data on a maps to get a general understanding of the spatial distribution of data.\nSummarize spatial data into table plots to compare how air quality differs in different socioeconomic conditions of international administrative areas."
  },
  {
    "objectID": "m203-grdiv1-pm25.html#introduction",
    "href": "m203-grdiv1-pm25.html#introduction",
    "title": "EJSCREEN tool",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#data-collection-and-integration",
    "href": "m203-grdiv1-pm25.html#data-collection-and-integration",
    "title": "EJSCREEN tool",
    "section": "Data Collection and Integration",
    "text": "Data Collection and Integration\nThe Global (GL) Annual PM2.5 Grids from MODIS, MISR and SeaWiFS Aerosol Optical Depth (AOD), v4.03 (1998 – 2019) can can be downloaded from the Socioeconomic Data and Applications Center ([SEDAC](https://sedac.ciesin.columbia.edu/)) (Center For International Earth Science Information Network-CIESIN-Columbia University 2022a).\nThe Global Gridded Relative Deprivation Index (GRDI), v1 (2010 – 2020) dataset can be downloaded from SEDAC as well (Center For International Earth Science Information Network-CIESIN-Columbia University 2022b).\nGather comprehensive datasets from reliable sources such as the US EPA’s EJSCREEN tool and other public health databases like John Hopkins and County Health Rankings. Integrate relevant environmental data (e.g., air pollutant concentrations, pollution source proximity) with health outcomes data (e.g., COVID-19 prevalence, NSCLC incidence). Ensure data compatibility and quality through data cleaning and validation procedures.\n\nPreparing Environment and Variables\nImporting python packages required:\n\nimport xarray as xr\nimport rioxarray\nimport rasterstats\nfrom rasterio.enums import Resampling\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport geopandas as gpd\nimport pygadm\n\nimport plotly.graph_objects as go \n\nLoad the GRDIv1 and PM2.5 data from local sources:\n\n# Load rasters\ngrdi_path = r\"Z:\\Sedac\\GRDI\\data\\povmap-grdi-v1-geotiff\\final data\\povmap-grdi-v1.tif\"\npm25_path = r\"F:\\TOPSSCHOOL\\git\\TOPSTSCHOOL-air-quality\\data\\sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-v4-gl-03-2019-geotiff\\sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-v4-gl-03-2019.tif\"\n\nUsing the package rasterio to load the data into memory. This allows us to read the data and use it for processing.\n\n# Open the input and reference rasters\ngrdi_raster = rioxarray.open_rasterio(grdi_path, mask_and_scale=True)\npm25_raster = rioxarray.open_rasterio(pm25_path, mask_and_scale=True)\n\n\n\nMatching Data Points using Bilinear Resample\nThe GRDI raster and PM2.5 rasters are incompatible in resolution. One method of harmonizing data is by using the Resampling bethod with a bilinear method. In this case, we reduce, or coarsen, the resolution of the GRDI raster to match the PM2.5 raster.\n\n# Resample the input raster to match the reference raster\ngrdi_raster = grdi_raster.rio.reproject_match(pm25_raster,resampling=Resampling.bilinear)"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#the-data-science-life-cycle",
    "href": "m203-grdiv1-pm25.html#the-data-science-life-cycle",
    "title": "EJSCREEN tool",
    "section": "The Data Science Life Cycle",
    "text": "The Data Science Life Cycle\nThe data science life cycle guides the systematic approach to handling data from collection to interpretation:\n\nData Acquisition\nObtain relevant datasets from sources like EJSCREEN, County Health Rankings, and specific studies’ databases. ### Data Preparation Clean and preprocess data to ensure accuracy and consistency, handling missing values and outliers appropriately.\n\n\nExploratory Data Analysis\nExplore data distributions, correlations, and initial insights to guide further analysis.\n\n\nModeling\nDevelop statistical models to test hypotheses and predict outcomes, considering factors like pollution exposure and demographic variables.\n\n\nEvaluation\nAssess model performance and validity through metrics and cross-validation techniques.\n\n\nDeployment\nCommunicate findings through reports, presentatio\nCongratulations! …. Now you should be able to:\n\nTest test…"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#module-2-air-quality-home",
    "href": "m203-grdiv1-pm25.html#module-2-air-quality-home",
    "title": "EJSCREEN tool",
    "section": "Module 2: Air Quality Home",
    "text": "Module 2: Air Quality Home\nIn this lesson, we explored ….\nModule 2: Air Quality"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#previewing-spatial-data-in-a-plot",
    "href": "m203-grdiv1-pm25.html#previewing-spatial-data-in-a-plot",
    "title": "EJSCREEN tool",
    "section": "Previewing Spatial Data in a Plot",
    "text": "Previewing Spatial Data in a Plot\n\n# Plotting the rasters\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 20))\n\n# Plot the original GRDI raster in the first subplot\nim1 = ax1.imshow(grdi_raster.values[0], cmap='viridis', interpolation='nearest')\nax1.set_title('Original GRDI Raster')\nfig.colorbar(im1, ax=ax1, orientation='horizontal', label='GRDI Values')\n\n# Plot the PM2.5 raster in the second subplot\nim2 = ax2.imshow(pm25_raster.values[0], cmap='hot', interpolation='nearest')\nax2.set_title('PM2.5 Raster')\nfig.colorbar(im2, ax=ax2, orientation='horizontal', label='PM2.5 Values')\n\n\n# Show the plots\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#working-with-administrative-data",
    "href": "m203-grdiv1-pm25.html#working-with-administrative-data",
    "title": "EJSCREEN tool",
    "section": "Working with administrative Data",
    "text": "Working with administrative Data\npygadm is a package that has international administrative units from levels 0 to 2. We can search the available countries by listing the Names.\n\ncountry_table = gpd.GeoDataFrame(pygadm.Names())\nlen(country_table)\n\n263\n\n\nSome available areas with a unique GID_0 code share Names; therefore we drop the rows that contain digits.\n\ncountry_table = country_table[~country_table['GID_0'].str.contains('\\d', na=False)]\nlen(country_table)\n\n254\n\n\n\nSubset Data From a Table\nDoing Zonal statistics for more than 200 countries may take a while, therefore, we can subset the data randomly with the .sample() method.\n\ncountry_sample = country_table.sample(n=15)\ncountry_sample\n\n\n\n\n\n  \n    \n      \n      NAME_0\n      GID_0\n    \n  \n  \n    \n      164\n      Mayotte\n      MYT\n    \n    \n      186\n      Poland\n      POL\n    \n    \n      184\n      Palau\n      PLW\n    \n    \n      93\n      Grenada\n      GRD\n    \n    \n      260\n      Zambia\n      ZMB\n    \n    \n      102\n      Haiti\n      HTI\n    \n    \n      41\n      Switzerland\n      CHE\n    \n    \n      180\n      Panama\n      PAN\n    \n    \n      239\n      United States Minor Outlying Isl\n      UMI\n    \n    \n      237\n      Uganda\n      UGA\n    \n    \n      182\n      Peru\n      PER\n    \n    \n      208\n      San Marino\n      SMR\n    \n    \n      158\n      Mauritania\n      MRT\n    \n    \n      63\n      Djibouti\n      DJI\n    \n    \n      61\n      Czechia\n      CZE"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#zonal-statistics-for-each-administrative-area",
    "href": "m203-grdiv1-pm25.html#zonal-statistics-for-each-administrative-area",
    "title": "EJSCREEN tool",
    "section": "Zonal Statistics for Each Administrative Area",
    "text": "Zonal Statistics for Each Administrative Area\nrasterstats has a funcion zonal_stats() which allows you to use vectors to summarize raster data. We summarize GRDIv1 data to calculate the following statistics: count, minimum, mean, max, median, standard deviation, range, and percentiles 20, 40, 60, and 80.\n\nstats_results = gpd.GeoDataFrame()\n\nfor index, row in country_sample.iloc[:].iterrows():\n    country = row['NAME_0']\n    country_GID = row['GID_0']\n    try:\n        country_poly =  pygadm.Items(admin=country_GID, content_level=0)\n    except:\n        print(country, \" skipped.\")\n        continue\n\n    # Create a mask for the polygons\n    grdi_country_zs= rasterstats.zonal_stats(country_poly, grdi_raster.values[0], affine=grdi_raster.rio.transform(), stats=\"count min mean max median std median range percentile_20 percentile_40 percentile_60 percentile_80\")\n    # # pm25_country_zs= rasterstats.zonal_stats(country_poly, pm25_arr, affine=pm25_transform, stats=\"count min mean max median std median range percentile_20 percentile_40 percentile_60 percentile_80\", nodata=pm25_raster.nodata)\n    # # Extract statistics into a dictionary\n    country_stats = {\n        'Country_Name': country,\n        'Country_GID' : country_GID,\n        'GRDI_Count': grdi_country_zs[0]['count'],\n        'GRDI_Min': grdi_country_zs[0]['min'],\n        'GRDI_Mean': grdi_country_zs[0]['mean'],\n        'GRDI_Max': grdi_country_zs[0]['max'],\n        'GRDI_Median': grdi_country_zs[0]['median'],\n        'GRDI_Std': grdi_country_zs[0]['std'],\n        'GRDI_Range': grdi_country_zs[0]['range'],\n        'GRDI_P20': grdi_country_zs[0]['percentile_20'],\n        'GRDI_P40': grdi_country_zs[0]['percentile_40'],\n        'GRDI_P60': grdi_country_zs[0]['percentile_60'],\n        'GRDI_P80': grdi_country_zs[0]['percentile_80'],\n        #     # 'PM25_Count': pm25_country_zs[0]['count'],\n        #     # 'PM25_Min': pm25_country_zs[0]['min'],\n        # 'PM25_Mean': pm25_country_zs[0]['mean'],\n        #     # 'PM25_Max': pm25_country_zs[0]['max'],\n        #     # 'PM25_Median': pm25_country_zs[0]['median'],\n        #     # 'PM25_Std': pm25_country_zs[0]['std'],\n        #     # 'PM25_Range': pm25_country_zs[0]['range'],\n        #     # 'PM25_P20': pm25_country_zs[0]['percentile_20'],\n        #     # 'PM25_P40': pm25_country_zs[0]['percentile_40'],\n        #     # 'PM25_P60': pm25_country_zs[0]['percentile_60'],\n        #     # 'PM25_P80': pm25_country_zs[0]['percentile_80'],\n        'geometry' : country_poly['geometry'].iloc[0]\n    }\n    country_stats_gdf = gpd.GeoDataFrame([country_stats], geometry='geometry')\n    # stats_results.append(country_stats_gdf)\n    stats_results = pd.concat([stats_results, country_stats_gdf], ignore_index=True)\n\nLet’s use the .head() method from Pandas to check the top of our table\n\nstats_results.head()\n\n\n\n\n\n  \n    \n      \n      Country_Name\n      Country_GID\n      GRDI_Count\n      GRDI_Min\n      GRDI_Mean\n      GRDI_Max\n      GRDI_Median\n      GRDI_Std\n      GRDI_Range\n      GRDI_P20\n      GRDI_P40\n      GRDI_P60\n      GRDI_P80\n      geometry\n    \n  \n  \n    \n      0\n      Mayotte\n      MYT\n      232\n      20.958664\n      60.282538\n      80.792061\n      64.474731\n      15.117578\n      59.833397\n      45.760521\n      58.921658\n      68.090202\n      74.339455\n      MULTIPOLYGON (((45.139 -13.004, 45.1382 -13.00...\n    \n    \n      1\n      Poland\n      POL\n      222239\n      2.237566\n      54.088715\n      67.701790\n      57.623749\n      12.010399\n      65.464223\n      47.988083\n      55.358624\n      60.313919\n      63.446243\n      MULTIPOLYGON (((19.0702 49.4128, 19.0539 49.41...\n    \n    \n      2\n      Palau\n      PLW\n      124\n      18.524588\n      64.073215\n      78.197929\n      69.165802\n      13.250177\n      59.673342\n      58.653236\n      67.722740\n      71.207588\n      72.446625\n      MULTIPOLYGON (((131.8116 2.9755, 131.8121 2.97...\n    \n    \n      3\n      Grenada\n      GRD\n      236\n      25.155468\n      57.231814\n      71.918877\n      58.063988\n      9.291824\n      46.763409\n      50.041462\n      56.093117\n      61.220333\n      65.207016\n      MULTIPOLYGON (((-61.7854 11.9879, -61.7851 11....\n    \n    \n      4\n      Zambia\n      ZMB\n      193019\n      23.992313\n      90.845026\n      98.482010\n      91.288452\n      4.815937\n      74.489697\n      90.092133\n      91.145348\n      91.480919\n      93.030083\n      MULTIPOLYGON (((25.8783 -17.9722, 25.8599 -17...."
  },
  {
    "objectID": "m203-grdiv1-pm25.html#defining-a-funtion",
    "href": "m203-grdiv1-pm25.html#defining-a-funtion",
    "title": "EJSCREEN tool",
    "section": "Defining a Funtion",
    "text": "Defining a Funtion\nWe can create a custom function that can allow us to use the zonal statistics process multiple times. A custom function can be created using the def FUNCTION_NAME(PARAMETER1, PARAMETER2): fuction to define what the fucntion will do.\n\ndef calculate_country_stats(country_sample, grdi_raster, pm25_raster=None):\n    \"\"\"\n    Calculate statistics for each country in the sample.\n\n    Parameters:\n    - country_sample: A pandas DataFrame containing country information with 'NAME_0' and 'GID_0' columns, in this case the country_table.\n    - grdi_raster: A raster object with which to perform the zonal statistics.\n    - pm25_raster: (Optional) A raster object for PM2.5 data. If provided, statistics will also be calculated for this raster.\n\n    Returns:\n    - stats_results: A GeoDataFrame containing the statistics for each country.\n    \"\"\"\n    stats_results = gpd.GeoDataFrame()\n\n    for index, row in country_sample.iloc[:].iterrows():\n        country = row['NAME_0']\n        country_GID = row['GID_0']\n        try:\n            country_poly = pygadm.Items(admin=country_GID, content_level=0)\n        except Exception as e:\n            print(country, \"skipped due to error:\", e)\n            continue\n\n        # Create a mask for the polygons and perform zonal statistics on GRDI raster\n        grdi_country_zs = rasterstats.zonal_stats(\n            country_poly, grdi_raster.values[0], \n            affine=grdi_raster.rio.transform(), \n            stats=\"count min mean max median std range percentile_20 percentile_40 percentile_60 percentile_80\"\n        )\n\n        # Uncomment and update the following lines if you want to include PM2.5 statistics\n        # if pm25_raster is not None:\n        #     pm25_country_zs = rasterstats.zonal_stats(\n        #         country_poly, pm25_raster.values[0], \n        #         affine=pm25_raster.rio.transform(), \n        #         stats=\"count min mean max median std range percentile_20 percentile_40 percentile_60 percentile_80\", \n        #         nodata=pm25_raster.nodata\n        #     )\n\n        # Extract statistics into a dictionary\n        country_stats = {\n            'Country_Name': country,\n            'Country_GID' : country_GID,\n            'GRDI_Count': grdi_country_zs[0]['count'],\n            'GRDI_Min': grdi_country_zs[0]['min'],\n            'GRDI_Mean': grdi_country_zs[0]['mean'],\n            'GRDI_Max': grdi_country_zs[0]['max'],\n            'GRDI_Median': grdi_country_zs[0]['median'],\n            'GRDI_Std': grdi_country_zs[0]['std'],\n            'GRDI_Range': grdi_country_zs[0]['range'],\n            'GRDI_P20': grdi_country_zs[0]['percentile_20'],\n            'GRDI_P40': grdi_country_zs[0]['percentile_40'],\n            'GRDI_P60': grdi_country_zs[0]['percentile_60'],\n            'GRDI_P80': grdi_country_zs[0]['percentile_80'],\n            'geometry' : country_poly['geometry'].iloc[0]\n        }\n\n        # If PM2.5 statistics are calculated, add them to the dictionary\n        # if pm25_raster is not None:\n        #     country_stats.update({\n        #         'PM25_Count': pm25_country_zs[0]['count'],\n        #         'PM25_Min': pm25_country_zs[0]['min'],\n        #         'PM25_Mean': pm25_country_zs[0]['mean'],\n        #         'PM25_Max': pm25_country_zs[0]['max'],\n        #         'PM25_Median': pm25_country_zs[0]['median'],\n        #         'PM25_Std': pm25_country_zs[0]['std'],\n        #         'PM25_Range': pm25_country_zs[0]['range'],\n        #         'PM25_P20': pm25_country_zs[0]['percentile_20'],\n        #         'PM25_P40': pm25_country_zs[0]['percentile_40'],\n        #         'PM25_P60': pm25_country_zs[0]['percentile_60'],\n        #         'PM25_P80': pm25_country_zs[0]['percentile_80'],\n        #     })\n\n        country_stats_gdf = gpd.GeoDataFrame([country_stats], geometry='geometry')\n        stats_results = pd.concat([stats_results, country_stats_gdf], ignore_index=True)\n\n    return stats_results\n\nFrom the table above, we can choose an attribute, or column, to display it in a map plot. In this case, I’m choosing the GRDI Max\n\ncolumn_chosen = 'GRDI_Max' #GRDI_Max, GRDI_Min, GRDI_Median\n# Plotting\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\nstats_results.plot(column=column_chosen, ax=ax, legend=True,\n    legend_kwds={'label': f\"{column_chosen} per country.\",\n                      'orientation': \"horizontal\"})\nax.set_title('Choropleth Map Showing GRDI Mean per country')\nax.set_axis_off()  # Turn off the axis numbers and ticks\nplt.show()\n\n\n\n\n\nSelecting Data by Column\nStart my creating a list of countries that you are interested in to Subset data from the DataFrame that match the values in the NAME_0 column. The .isin() mehthod checks each element in the DataFrame’s column for the item present in the list and returns matching rows.\n\n# selected_countries = [\"Algeria\", \"Somalia\", \"Colombia\", \"Timor Leste\", \"Finland\", \"Nicaragua\", \"United Kingdom\", \"Mali\"]\n# selected_countries = [\"Anguilla\", \"Armenia\", \"Angola\", \"Argentina\", \"Albania\", \"United Arab Emirates\", \"American Samoa\", \"Australia\" ]\nselected_countries = [\"Algeria\", \"Somalia\", \"Colombia\", \"Timor Leste\", \"Finland\", \"Nicaragua\", \"United Kingdom\", \"Mali\", \"Armenia\", \"Argentina\",  \"Albania\", \"United Arab Emirates\", \"Indonesia\", \"Qatar\"]\n\n#use the list above to subset the country_table DataFrame by the column NAME_0 \nselected_countries = country_table[country_table['NAME_0'].isin(selected_countries)]\n\n\n\nUsing a Defined Custom Function\nRecalling the defined fucntion calculate_country_stats, we can use our selected_countries list, and the GRDI and PM2.5 rasters, to create a new table of zonal statistics.\n\nstats_results = calculate_country_stats(selected_countries, grdi_raster)\n\nShow the head of the table again:\n\nstats_results.head()\n\n\n\n\n\n  \n    \n      \n      Country_Name\n      Country_GID\n      GRDI_Count\n      GRDI_Min\n      GRDI_Mean\n      GRDI_Max\n      GRDI_Median\n      GRDI_Std\n      GRDI_Range\n      GRDI_P20\n      GRDI_P40\n      GRDI_P60\n      GRDI_P80\n      geometry\n    \n  \n  \n    \n      0\n      Albania\n      ALB\n      19076\n      8.272310\n      61.513866\n      75.395561\n      66.220139\n      11.644754\n      67.123251\n      55.861691\n      64.445587\n      67.104332\n      68.589424\n      MULTIPOLYGON (((20.0541 39.6917, 20.0389 39.69...\n    \n    \n      1\n      United Arab Emirates\n      ARE\n      18229\n      5.732072\n      42.347647\n      67.470955\n      45.034630\n      17.949307\n      61.738883\n      24.688160\n      38.623692\n      50.710217\n      61.909931\n      MULTIPOLYGON (((54.1541 22.7548, 53.3313 22.85...\n    \n    \n      2\n      Argentina\n      ARG\n      474297\n      7.572341\n      66.341158\n      81.701645\n      68.789696\n      10.416561\n      74.129304\n      66.774643\n      68.278297\n      69.335510\n      71.098465\n      MULTIPOLYGON (((-66.5458 -55.061, -66.5486 -55...\n    \n    \n      3\n      Armenia\n      ARM\n      9108\n      6.944193\n      59.871617\n      73.707901\n      64.272858\n      12.315193\n      66.763708\n      52.692970\n      61.288189\n      66.743027\n      69.004845\n      MULTIPOLYGON (((45.8319 39.8311, 45.8448 39.82...\n    \n    \n      4\n      Colombia\n      COL\n      223557\n      11.956444\n      71.523674\n      84.922409\n      73.350586\n      8.762370\n      72.965965\n      69.966934\n      72.190056\n      74.405403\n      76.502792\n      MULTIPOLYGON (((-77.491 4.1451, -77.4985 4.140...\n    \n  \n\n\n\n\nPlot the map again choosing a column to plot:\n\ncolumn_chosen = 'GRDI_Max' #GRDI_Max, GRDI_Min, GRDI_Median\nstats_results.plot()\nplt.show()"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#creating-a-table-with-results",
    "href": "m203-grdiv1-pm25.html#creating-a-table-with-results",
    "title": "EJSCREEN tool",
    "section": "Creating a Table with Results",
    "text": "Creating a Table with Results\nWe can create a list of tuples that we can use to refer to the GRDI statistical values, and the name, color, and symbol we want to assign. In this case, we are using the GRDI zonal statistics of each country we selected that include the Mean, Minimum, Maximum, and interquartiles.\n\n# List of GRDI values and their corresponding properties\n#column, value name, color, symbol\ngrdi_data = [\n    ('GRDI_Mean', 'Mean', 'orange', 'diamond'),\n    ('GRDI_Min', 'Min', 'gray', '152'),\n    ('GRDI_Max', 'Max', 'gray', '151'),\n    ('GRDI_P20', 'Q20', 'blue', '142'),\n    ('GRDI_P40', 'Q40', 'purple', '142'),\n    ('GRDI_P60', 'Q60', 'green', '142'),\n    ('GRDI_P80', 'Q80', 'red', '142')\n]\n\nWe can create a figure to display the data based on the names colors and symbols we selected.\n\n# Create a figure\nfig = go.Figure()\n\n# Add traces to the figure based on the data\nfor col, name, color, symbol in grdi_data:\n    fig.add_trace(go.Scatter(\n        x=stats_results[col],\n        y=stats_results['Country_Name'],\n        mode='markers',\n        name=name,\n        marker=dict(color=color, size=10, symbol=symbol)\n    ))\n\n# Customize layout\nfig.update_layout(\n    title='GRDI Statistics by Country',\n    xaxis_title='GRDI Values',\n    yaxis_title='Country Name',\n    yaxis=dict(tickmode='linear'),\n    legend_title='Statistics',\n    yaxis_type='category',\n    xaxis=dict(tickvals=[0, 20, 40, 60, 80, 100])\n)\n\n# Show plot\nfig.show()"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#summarizing-pm2.5-values-by-socioeconomic-deprivation",
    "href": "m203-grdiv1-pm25.html#summarizing-pm2.5-values-by-socioeconomic-deprivation",
    "title": "EJSCREEN tool",
    "section": "Summarizing PM2.5 Values by Socioeconomic Deprivation",
    "text": "Summarizing PM2.5 Values by Socioeconomic Deprivation\nConsidering the GRDI quartile values as a level of socieoeconomic deprivation within each country, we can use the stats_results GeoDataFrame, the GRDI raster, and the PM2.5 raster to calculate the Mean PM.25 value within each of those areas in each country. This can describe how the air quality for different socioeconomic strata compare within the country, as well as against other countries.\nThe results will be added to the stats_results with the corresponting columns.\n\n# iterate through the stats_results table rows\nfor index, row in stats_results.iloc[:].iterrows():\n    #isolate each country's respective row\n    row_df = gpd.GeoDataFrame([row], geometry='geometry').reset_index(drop=True)\n    print(row_df.loc[0,'Country_GID'])\n    try:\n        #use rioxarray to clip the GRDI and PM2.5 rasters by the geometry of the respective country.\n        grdi_country = grdi_raster.rio.clip(row_df.geometry, grdi_raster.rio.crs)\n        pm25_country = pm25_raster.rio.clip(row_df.geometry, grdi_raster.rio.crs)\n    except:\n        print('Error in clip')\n        continue\n\n    #Applying squeeze() to this array removes the singleton dimension, reducing it to a 2D array with dimensions (rows, columns)\n    grdi_country= grdi_country.squeeze()\n    pm25_country= pm25_country.squeeze()\n\n\n    # Subset the GRDI raster where values fall between each GRDI quintiles\n    grdi_countryQ1 = grdi_country.where((grdi_country >= row_df.loc[0, 'GRDI_Min']) & (grdi_country <= row_df.loc[0, 'GRDI_P20']))\n    grdi_countryQ2 = grdi_country.where((grdi_country >= row_df.loc[0, 'GRDI_P20']) & (grdi_country <= row_df.loc[0, 'GRDI_P40']))\n    grdi_countryQ3 = grdi_country.where((grdi_country >= row_df.loc[0, 'GRDI_P40']) & (grdi_country <= row_df.loc[0, 'GRDI_P60']))\n    grdi_countryQ4 = grdi_country.where((grdi_country >= row_df.loc[0, 'GRDI_P60']) & (grdi_country <= row_df.loc[0, 'GRDI_P80']))\n    grdi_countryQ5 = grdi_country.where((grdi_country >= row_df.loc[0, 'GRDI_P80']) & (grdi_country <= row_df.loc[0, 'GRDI_Max']))\n\n\n    # Mask the PM2.5 raster using the above GRDI quartile rasters, keeping only the cells that intersect\n    pm25_countryQ1 = pm25_country.where(grdi_countryQ1.notnull())\n    pm25_countryQ2 = pm25_country.where(grdi_countryQ2.notnull())\n    pm25_countryQ3 = pm25_country.where(grdi_countryQ3.notnull())\n    pm25_countryQ4 = pm25_country.where(grdi_countryQ4.notnull())\n    pm25_countryQ5 = pm25_country.where(grdi_countryQ5.notnull())\n\n    #Find the mean value of of the intersected PM2.5 rasters in each quartile\n    pm25_countryQ1v = pm25_countryQ1.mean().item()\n    pm25_countryQ2v = pm25_countryQ2.mean().item()\n    pm25_countryQ3v = pm25_countryQ3.mean().item()\n    pm25_countryQ4v = pm25_countryQ4.mean().item()\n    pm25_countryQ5v = pm25_countryQ5.mean().item()\n\n    #add the resuts to the stats_results table in the respective column\n    stats_results.at[index, 'PM25_Q1'] = pm25_countryQ1v\n    stats_results.at[index, 'PM25_Q2'] = pm25_countryQ2v\n    stats_results.at[index, 'PM25_Q3'] = pm25_countryQ3v\n    stats_results.at[index, 'PM25_Q4'] = pm25_countryQ4v\n    stats_results.at[index, 'PM25_Q5'] = pm25_countryQ5v\n\nALB\n\n\nARE\n\n\nARG\n\n\nARM\n\n\nCOL\n\n\nDZA\n\n\nFIN\n\n\nGBR\n\n\nIDN\n\n\nMLI\n\n\nNIC\n\n\nQAT\n\n\nSOM\n\n\n\nstats_results.head()\n\n\n\n\n\n  \n    \n      \n      Country_Name\n      Country_GID\n      GRDI_Count\n      GRDI_Min\n      GRDI_Mean\n      GRDI_Max\n      GRDI_Median\n      GRDI_Std\n      GRDI_Range\n      GRDI_P20\n      GRDI_P40\n      GRDI_P60\n      GRDI_P80\n      geometry\n      PM25_Q1\n      PM25_Q2\n      PM25_Q3\n      PM25_Q4\n      PM25_Q5\n    \n  \n  \n    \n      0\n      Albania\n      ALB\n      19076\n      8.272310\n      61.513866\n      75.395561\n      66.220139\n      11.644754\n      67.123251\n      55.861691\n      64.445587\n      67.104332\n      68.589424\n      MULTIPOLYGON (((20.0541 39.6917, 20.0389 39.69...\n      15.438293\n      15.031855\n      14.699892\n      14.612475\n      15.709009\n    \n    \n      1\n      United Arab Emirates\n      ARE\n      18229\n      5.732072\n      42.347647\n      67.470955\n      45.034630\n      17.949307\n      61.738883\n      24.688160\n      38.623692\n      50.710217\n      61.909931\n      MULTIPOLYGON (((54.1541 22.7548, 53.3313 22.85...\n      47.710175\n      47.893559\n      47.822292\n      48.220722\n      49.729328\n    \n    \n      2\n      Argentina\n      ARG\n      474297\n      7.572341\n      66.341158\n      81.701645\n      68.789696\n      10.416561\n      74.129304\n      66.774643\n      68.278297\n      69.335510\n      71.098465\n      MULTIPOLYGON (((-66.5458 -55.061, -66.5486 -55...\n      7.519970\n      5.924110\n      6.083218\n      7.562082\n      8.672854\n    \n    \n      3\n      Armenia\n      ARM\n      9108\n      6.944193\n      59.871617\n      73.707901\n      64.272858\n      12.315193\n      66.763708\n      52.692970\n      61.288189\n      66.743027\n      69.004845\n      MULTIPOLYGON (((45.8319 39.8311, 45.8448 39.82...\n      19.292490\n      16.728804\n      16.334721\n      16.337336\n      15.342737\n    \n    \n      4\n      Colombia\n      COL\n      223557\n      11.956444\n      71.523674\n      84.922409\n      73.350586\n      8.762370\n      72.965965\n      69.966934\n      72.190056\n      74.405403\n      76.502792\n      MULTIPOLYGON (((-77.491 4.1451, -77.4985 4.140...\n      27.425064\n      29.047859\n      24.132767\n      22.309097\n      20.367249"
  },
  {
    "objectID": "m203-grdiv1-pm25.html#plot-results-of-mean-pm2.5-in-socieceonomic-deprivation-quartiles-per-country",
    "href": "m203-grdiv1-pm25.html#plot-results-of-mean-pm2.5-in-socieceonomic-deprivation-quartiles-per-country",
    "title": "EJSCREEN tool",
    "section": "Plot Results of Mean PM2.5 in Socieceonomic Deprivation Quartiles per country",
    "text": "Plot Results of Mean PM2.5 in Socieceonomic Deprivation Quartiles per country\nSimilarly, we create a list of tuples of how we want to display the data, and create a figure based on the tuples. This plot would show each country in the y axis and the Log of Mean PM2.5 values in each country’s GRDI quarties.\n\n# List of GRDI values and their corresponding properties\n#column, value name, color, symbol\nplot_data =[\n    ('PM25_Q1', 'Q1', '#440154', '6'),  # Light Blue\n    ('PM25_Q2', 'Q2', '#31688E', '5'),  # Light Green\n    ('PM25_Q3', 'Q3', '#35B779', '7'),  # Yellow\n    ('PM25_Q4', 'Q4', '#FDE725', '8'),  # Orange\n    ('PM25_Q5', 'Q5', '#FF0000', '1')   # Red\n]\n\n# Create a figure\nfig = go.Figure()\n\n# Add traces to the figure.\nfor col, name, color, symbol in plot_data:\n    xlog  = np.log(stats_results[col])\n    fig.add_trace(go.Scatter(\n        x=xlog,\n        y=stats_results['Country_Name'],\n        mode='markers+text',  # Add 'text' to mode\n        text=[f'<b>{name}</b>' for _ in stats_results[col]],  # Repeat name for each point\n        name=name,\n        textfont=dict(color=color, size=12),\n        textposition='top center',  # Position the text above the symbol\n        marker_color=color,\n        marker_line_color=\"midnightblue\",\n        marker_symbol=symbol,\n        marker_size=14,\n        marker_line_width=2,\n        marker_opacity=0.6\n        ))\nfig.update_traces(textposition='top center')\n\n    # Customize layout\nfig.update_layout(\n    title='Mean PM2.5 in each GRDI Quartile by Country',\n    xaxis_title='Log of PM2.5 Mean Values',\n    yaxis_title='Country Name',\n    yaxis=dict(tickmode='linear'),\n    legend_title='Statistics',\n    yaxis_type='category',\n    xaxis=dict(rangemode=\"tozero\"),\n    \n    #xaxis=dict(tickvals=[0, 20, 40, 60, 80, 100])\n    )\n\n# Show plot\nfig.show()\n\n\n                                                \n\n\nWith this shapely plot, We can examine differences between countires and PM2.5 values. The plot displays the coutnries on the Y axis and log values of the average PM2.5 value on the X axis. Each country displays PM2.5 values averaged within the quartile areas based on GRDI values of each country. A higher quartile (Q) implies a higher degree of deprivation, 1 being the lowest and 5 the highest.\nCongratulations! …. Now you should be able to:\n\nTest test…"
  }
]